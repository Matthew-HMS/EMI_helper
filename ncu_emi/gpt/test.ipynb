{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key = os.environ.get('OPENAI_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: vs_ufG9bpIsSvAwICPjAjO9Yci5, Name: Algorithm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "api_endpoint = \"https://api.openai.com/v1/vector_stores\"\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "# 定義請求標頭\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"OpenAI-Beta\": \"assistants=v2\"\n",
    "}\n",
    "\n",
    "# 發送GET請求以獲取所有的vector stores\n",
    "response = requests.get(api_endpoint, headers=headers)\n",
    "\n",
    "# 檢查請求是否成功\n",
    "if response.status_code == 200:\n",
    "    vector_stores = response.json()\n",
    "    # 列出所有的vector stores\n",
    "    for store in vector_stores['data']:\n",
    "        print(f\"ID: {store['id']}, Name: {store['name']}\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve vector stores: {response.status_code} {response.text}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: file-W0SutWWSidJoAqCnnYl5unXx, Name: 改良QuickSort作業說明_更正.pdf\n",
      "ID: file-2dUC8dbXr1pOPzcfiNqYCQEH, Name: Eclipse安裝與輸出說明.pdf\n"
     ]
    }
   ],
   "source": [
    "api_endpoint2 = \"https://api.openai.com/v1/files\"\n",
    "\n",
    "response2 = requests.get(api_endpoint2, headers=headers)\n",
    "\n",
    "if response2.status_code == 200:\n",
    "    vector_stores = response2.json()\n",
    "    # 列出所有的vector stores\n",
    "    for store in vector_stores['data']:\n",
    "        print(f\"ID: {store['id']}, Name: {store['filename']}\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve vector stores: {response2.status_code} {response2.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=2, failed=0, in_progress=0, total=2)\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.beta.vector_stores.create(name=\"Algorithm\")\n",
    "\n",
    "# file_paths = [\"改良QuickSort作業說明_更正.pdf\",\"Eclipse安裝與輸出說明.pdf\",\"chapter5.pdf\"]\n",
    "file_paths = [\"改良QuickSort作業說明_更正.pdf\",\"Eclipse安裝與輸出說明.pdf\"]\n",
    "file_streams = [open(file_path, \"rb\") for file_path in file_paths]\n",
    "\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Algorithm\",\n",
    "  instructions=\"1. You are now an assistant for the professor in algorithm class, you need to teach the class in English 2. Read pdf's content and give me an English script for class 3. Use the knowledge only in the pdf, else don't answer and say you don't know\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"file_search\"}, {\"type\": \"vision\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thread(id='thread_iunQSuuimspsMJH7OK92SBL9', created_at=1719808789, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "\n",
    "thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"briefly explain chapter5.\"\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "print(thread.tool_resources.file_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id, assistant_id=assistant.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot provide the full content you requested from the file as it is written in Chinese, and I am instructed to produce only English content based strictly on the file provided. If you can offer an English document or need specific help with any part of the algorithm content described in Chapter 5, please let me know!\n"
     ]
    }
   ],
   "source": [
    "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "# print(messages)\n",
    "print(messages[0].content[0].text.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncu_emi_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
